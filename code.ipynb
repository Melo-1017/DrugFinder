{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This item imports some commonly used pre-training models\n",
    "pip install bio-embeddings[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,cohen_kappa_score,confusion_matrix,roc_curve,auc,roc_auc_score\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tool functions\n",
    "def getCls(vector):\n",
    "  vector=vector.mean(axis=0)\n",
    "  return vector\n",
    "def data_write(input_data,output_file_name):\n",
    "  embedder = ProtTransBertBFDEmbedder()\n",
    "  cnt=0\n",
    "  for i in input_data:\n",
    "    # if cnt<645:\n",
    "    #   cnt+=1\n",
    "    #   continue\n",
    "    embedding = embedder.embed(i)\n",
    "    cls=getCls(embedding)\n",
    "    cnt+=1\n",
    "    print(cnt)\n",
    "    print(cls)\n",
    "    if not os.path.exists(output_file_name):\n",
    "      os.system(r\"touch {}\".format(output_file_name))\n",
    "    with open(output_file_name,'a') as f:\n",
    "      f.write(str(cnt)+\"\\n\")\n",
    "      for j in cls:\n",
    "        f.write(str(j)+\" \")\n",
    "      f.write(\"\\n\")\n",
    "def readClsData(cls_datafile,cls_data):\n",
    "    cnt=0\n",
    "    with open(cls_datafile,\"r\") as f:\n",
    "        d=f.readline()\n",
    "        while d:\n",
    "            d=f.readline().split() \n",
    "            if d:\n",
    "                temp=[]\n",
    "                for i in d:\n",
    "                    i=float(i)\n",
    "                    temp.append(i)\n",
    "                cnt+=1\n",
    "                cls_data.append(temp)\n",
    "            f.readline()\n",
    "def readTgData(file_name):\n",
    "    lists = []\n",
    "    with open(file_name, \"r\") as f:\n",
    "        d = f.readline()\n",
    "        while d != '\\n' and d:\n",
    "            line = f.readline()\n",
    "            li = line.split(\" \")\n",
    "            lists.append(li)\n",
    "            d = f.readline()\n",
    "    return lists\n",
    "def modelPerformance(y_true, y_pred):\n",
    "    print('-------------------------------------------------------------')\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, _, _ = roc_curve(y_pred, y_true)\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "    print('ACC: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Sn: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('Sp: ' + str(1 - fpr[1]))\n",
    "    print(\"F1: \" + str(f1_score(y_true, y_pred)))\n",
    "    print(\"Kappa: \" + str(cohen_kappa_score(y_true, y_pred)))\n",
    "    print(\"MCC: \" + str(matthews_corrcoef(y_true, y_pred)))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get origin data\n",
    "path_ne_train=\"/Data/MyDrive/Colab Notebooks/data/negative_train.txt\"\n",
    "path_ne_test=\"/Data/MyDrive/Colab Notebooks/data/negative_test.txt\"\n",
    "path_po_train=\"/Data/MyDrive/Colab Notebooks/data/positive_train.txt\"\n",
    "path_po_test=\"/Data/MyDrive/Colab Notebooks/data/positive_test.txt\"\n",
    "negative_train=[]\n",
    "negative_test=[]\n",
    "positive_train=[]\n",
    "positive_test=[]\n",
    "\n",
    "with open (path_ne_train,\"r\") as f:\n",
    "    d=f.readline()\n",
    "    while d:\n",
    "        d=f.readline().strip()\n",
    "        f.readline()\n",
    "        if d:\n",
    "          negative_train.append(d)\n",
    "    print(len(negative_train))\n",
    "    \n",
    "with open (path_ne_test,\"r\") as f:\n",
    "    d=f.readline()\n",
    "    while d:\n",
    "        d=f.readline().strip()\n",
    "        f.readline()\n",
    "        if d:\n",
    "            negative_test.append(d)\n",
    "    print(len(negative_test))\n",
    "\n",
    "with open (path_po_train,\"r\") as f:\n",
    "    d=f.readline()\n",
    "    while d:\n",
    "        d=f.readline().strip()\n",
    "        f.readline()\n",
    "        if d:\n",
    "            positive_train.append(d)\n",
    "    print(len(positive_train))\n",
    "    \n",
    "with open (path_po_test,\"r\") as f:\n",
    "    d=f.readline()\n",
    "    while d:\n",
    "        d=f.readline().strip()\n",
    "        f.readline()\n",
    "        if d:\n",
    "            positive_test.append(d)\n",
    "    print(len(positive_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training model features\n",
    "path_ne_train_cls=\"/Data/MyDrive/Colab Notebooks/data/negative_train_cls.txt\"\n",
    "path_ne_test_cls=\"/Data/MyDrive/Colab Notebooks/data/negative_test_cls.txt\"\n",
    "path_po_train_cls=\"/Data/MyDrive/Colab Notebooks/data/positive_train_cls.txt\"\n",
    "path_po_test_cls=\"/Data/MyDrive/Colab Notebooks/data/positive_test_cls.txt\"\n",
    "data_write(negative_train,path_ne_train_cls)\n",
    "data_write(negative_test,path_ne_test_cls)\n",
    "data_write(positive_train,path_po_train_cls)\n",
    "data_write(positive_test,path_po_test_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module reads pssm features, and all pssm features are generated by POSSUM. Check our paper for details.\n",
    "# kp pssm\n",
    "kp_ne_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/kp_ne_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(kp_ne_test.shape)\n",
    "\n",
    "kp_ne_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/kp_ne_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(kp_ne_train.shape)\n",
    "\n",
    "kp_po_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/kp_po_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(kp_po_test.shape)\n",
    "\n",
    "kp_po_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/kp_po_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(kp_po_train.shape)\n",
    "\n",
    "# dpc pssm\n",
    "dpc_ne_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/dpc_ne_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(dpc_ne_test.shape)\n",
    "\n",
    "dpc_ne_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/dpc_ne_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(dpc_ne_train.shape)\n",
    "\n",
    "dpc_po_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/dpc_po_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(dpc_po_test.shape)\n",
    "\n",
    "dpc_po_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/dpc_po_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(dpc_po_train.shape)\n",
    "\n",
    "# sf pssm\n",
    "sf_ne_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/sf_ne_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(sf_ne_test.shape)\n",
    "\n",
    "sf_ne_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/sf_ne_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(sf_ne_train.shape)\n",
    "\n",
    "sf_po_test = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/sf_po_test.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(sf_po_test.shape)\n",
    "\n",
    "sf_po_train = np.loadtxt(open(\"/Data/MyDrive/Colab Notebooks/data/sf_po_train.csv\",\"rb\"),delimiter=\",\",skiprows=1)\n",
    "print(sf_po_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module performs feature selection operations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1,max_depth=3)\n",
    "forest.fit(x_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# combine features\n",
    "a=np.hstack([np.array(positive_train_cls),kp_po_train,dpc_po_train,sf_po_train])\n",
    "b=np.hstack([np.array(negative_train_cls),kp_ne_train,dpc_ne_train,sf_ne_train])\n",
    "x_train=np.vstack([a,b])\n",
    "\n",
    "a=np.hstack([np.array(positive_test_cls),kp_po_test,dpc_po_test,sf_po_test])\n",
    "b=np.hstack([np.array(negative_test_cls),kp_ne_test,dpc_ne_test,sf_ne_test])\n",
    "x_test=np.vstack([a,b])\n",
    "\n",
    "y_train=np.hstack([np.ones(1005), np.zeros(1059)])\n",
    "y_test=np.hstack([np.ones(218), np.zeros(260)])\n",
    "\n",
    "x_train_select=[]\n",
    "x_test_select=[]\n",
    "\n",
    "K=1500 # This value represents the features length\n",
    "\n",
    "for i in x_train:\n",
    "  traint=[]\n",
    "  for k in indices[0:K]:\n",
    "    traint.append(i[k])\n",
    "  x_train_select.append(traint)\n",
    "for i in x_test:\n",
    "  testt=[]\n",
    "  for k in indices[0:K]:\n",
    "    testt.append(i[k])\n",
    "  x_test_select.append(testt)\n",
    "x_train_select=np.array(x_train_select)\n",
    "x_test_select=np.array(x_test_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module performs performance testing and draws ROC curves\n",
    "# There may be some redundant code written to implement different functions. Please enable the corresponding code according to the purpose, and do not run all the code at once.\n",
    "# plt.figure(figsize=(15,4))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('T5')\n",
    "\n",
    "\n",
    "x_train=x_train_select \n",
    "x_test=x_test_select \n",
    "\n",
    "smodel5 = svm.SVC(gamma='scale', \n",
    "          C=10, \n",
    "          decision_function_shape='ovr', \n",
    "          kernel='rbf')\n",
    "smodel5.fit(x_train,y_train)\n",
    "result=smodel5.predict(x_test)\n",
    "modelPerformance(y_test,result)\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,smodel1.decision_function(x_test))\n",
    "# auc = roc_auc_score(y_test,smodel1.decision_function(x_test))\n",
    "# plt.plot(fpr,tpr,color='darkgoldenrod',label='SVM (AUC = %0.2f)'%auc)\n",
    "\n",
    "forest1 = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1,max_depth=3)\n",
    "forest1.fit(x_train, y_train)\n",
    "result=forest1.predict(x_test)\n",
    "modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,forest1.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,forest1.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='red',label='RF (AUC = %0.2f)'%auc)\n",
    "\n",
    "NB1 = GaussianNB()\n",
    "NB1.fit(x_train, y_train)\n",
    "result=NB1.predict(x_test)\n",
    "modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,NB1.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,NB1.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='orange',label='NB (AUC = %0.2f)'%auc)\n",
    "\n",
    "XGB1 = XGBClassifier(max_depth=15,\n",
    "          learning_rate=0.1,\n",
    "          n_estimators=2000,\n",
    "          min_child_weight=5,\n",
    "          max_delta_step=0,\n",
    "          subsample=0.8,\n",
    "          colsample_bytree=0.7,\n",
    "          reg_alpha=0,\n",
    "          reg_lambda=0.4,\n",
    "          scale_pos_weight=0.8,\n",
    "          objective='binary:logistic',\n",
    "          eval_metric='auc',\n",
    "          seed=1440,\n",
    "          gamma=0)\n",
    "XGB1.fit(x_train, y_train)\n",
    "y_pred = XGB1.predict(x_test)\n",
    "result = [round(value) for value in y_pred]\n",
    "modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,XGB1.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,XGB1.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='dodgerblue',label='XGB (AUC = %0.2f)'%auc)\n",
    "\n",
    "knc1 = KNN(n_neighbors =5)\n",
    "knc1.fit(x_train,y_train)\n",
    "result = knc1.predict(x_test)\n",
    "modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,knc1.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,knc1.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='purple',label='KNN (AUC = %0.2f)'%auc)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('PBD')\n",
    "\n",
    "\n",
    "# x_train=trainPBD \n",
    "# x_test=testPBD  \n",
    "\n",
    "# # smodel2 = svm.SVC(gamma='scale', \n",
    "# #           C=10, \n",
    "# #           decision_function_shape='ovr', \n",
    "# #           kernel='rbf')\n",
    "# # smodel2.fit(x_train,y_train)\n",
    "# # result=smodel2.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,smodel2.decision_function(x_test))\n",
    "# auc = roc_auc_score(y_test,smodel2.decision_function(x_test))\n",
    "# plt.plot(fpr,tpr,color='darkgoldenrod',label='SVM (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # forest2 = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1,max_depth=3)\n",
    "# # forest2.fit(x_train, y_train)\n",
    "# # result=forest2.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,forest2.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,forest2.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='red',label='RF (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # NB2 = GaussianNB()\n",
    "# # NB2.fit(x_train, y_train)\n",
    "# # result=NB2.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,NB2.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,NB2.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='orange',label='NB (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # XGB2 = XGBClassifier(max_depth=15,\n",
    "# #           learning_rate=0.1,\n",
    "# #           n_estimators=2000,\n",
    "# #           min_child_weight=5,\n",
    "# #           max_delta_step=0,\n",
    "# #           subsample=0.8,\n",
    "# #           colsample_bytree=0.7,\n",
    "# #           reg_alpha=0,\n",
    "# #           reg_lambda=0.4,\n",
    "# #           scale_pos_weight=0.8,\n",
    "# #           objective='binary:logistic',\n",
    "# #           eval_metric='auc',\n",
    "# #           seed=1440,\n",
    "# #           gamma=0)\n",
    "# # XGB2.fit(x_train, y_train)\n",
    "# # y_pred = XGB2.predict(x_test)\n",
    "# # result = [round(value) for value in y_pred]\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,XGB2.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,XGB2.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='dodgerblue',label='XGB (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # knc2 = KNN(n_neighbors =5)\n",
    "# # knc2.fit(x_train,y_train)\n",
    "# # result = knc2.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,knc2.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,knc2.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='purple',label='KNN (AUC = %0.2f)'%auc)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('SeqVec')\n",
    "\n",
    "\n",
    "# x_train=trainSEQ \n",
    "# x_test=testSEQ  \n",
    "\n",
    "# # smodel3 = svm.SVC(gamma='scale', \n",
    "# #           C=10, \n",
    "# #           decision_function_shape='ovr', \n",
    "# #           kernel='rbf')\n",
    "# # smodel3.fit(x_train,y_train)\n",
    "# # result=smodel3.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,smodel3.decision_function(x_test))\n",
    "# auc = roc_auc_score(y_test,smodel3.decision_function(x_test))\n",
    "# plt.plot(fpr,tpr,color='darkgoldenrod',label='SVM (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # forest3 = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1,max_depth=3)\n",
    "# # forest3.fit(x_train, y_train)\n",
    "# # result=forest3.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,forest3.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,forest3.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='red',label='RF (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # NB3 = GaussianNB()\n",
    "# # NB3.fit(x_train, y_train)\n",
    "# # result=NB3.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,NB3.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,NB3.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='orange',label='NB (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # XGB3 = XGBClassifier(max_depth=15,\n",
    "# #           learning_rate=0.1,\n",
    "# #           n_estimators=2000,\n",
    "# #           min_child_weight=5,\n",
    "# #           max_delta_step=0,\n",
    "# #           subsample=0.8,\n",
    "# #           colsample_bytree=0.7,\n",
    "# #           reg_alpha=0,\n",
    "# #           reg_lambda=0.4,\n",
    "# #           scale_pos_weight=0.8,\n",
    "# #           objective='binary:logistic',\n",
    "# #           eval_metric='auc',\n",
    "# #           seed=1440,\n",
    "# #           gamma=0)\n",
    "# # XGB3.fit(x_train, y_train)\n",
    "# # y_pred = XGB3.predict(x_test)\n",
    "# # result = [round(value) for value in y_pred]\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,XGB3.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,XGB3.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='dodgerblue',label='XGB (AUC = %0.2f)'%auc)\n",
    "\n",
    "# # knc3 = KNN(n_neighbors =5)\n",
    "# # knc3.fit(x_train,y_train)\n",
    "# # result = knc3.predict(x_test)\n",
    "# # modelPerformance(y_test,result)\n",
    "# auc = roc_auc_score(y_test,knc3.predict_proba(x_test)[:,1])\n",
    "# fpr,tpr, thresholds = roc_curve(y_test,knc3.predict_proba(x_test)[:,1])\n",
    "# plt.plot(fpr,tpr,color='purple',label='KNN (AUC = %0.2f)'%auc)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "# # plt.subplots_adjust(left=None,bottom=None,right=None,top=None,wspace=0.3,hspace=0.3)\n",
    "# plt.savefig(\"All Roc.svg\", dpi=300,format=\"svg\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
